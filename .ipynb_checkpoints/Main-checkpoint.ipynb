{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named cv2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-80ceca469dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyannote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfaceController\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asif/Downloads/Fyp2/Code/structure/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Herve BREDIN - http://herve.niderb.fr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mshot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;31m#from .thread import Thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/asif/Downloads/Fyp2/Code/structure/shot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named cv2"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import pyannote.core.json\n",
    "from structure.video import Video\n",
    "from structure.shot import Shot\n",
    "import faceController as fc\n",
    "from face.clustering import FaceClustering\n",
    "from pyannote.core import Timeline\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "from pandas import read_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/[username]/Applications/anaconda/envs/UdacityNanoCar/lib/python3.5/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def do_shot(video, output, height=50, window=2.0, threshold=1.0):\n",
    "    shots = Shot(video, height=height, context=window, threshold=threshold)\n",
    "    shots = Timeline(shots)\n",
    "    with open(output, 'w') as fp:\n",
    "        pyannote.core.json.dump(shots, fp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"sample4.mkv\"\n",
    "shotOutput =\"./extra/\"+filename.split(\".\")[0]+\"Shots.json\"\n",
    "landmark_model = \"./models/shape_predictor_68_face_landmarks.dat\"\n",
    "embedding_model = \"./models/dlib_face_recognition_resnet_model_v1.dat\"\n",
    "landmarks = \"./extra/\"+filename.split(\".\")[0]+\"Landmarks.txt\"\n",
    "tracking =  \"./extra/\"+filename.split(\".\")[0]+\"Tracking.txt\"\n",
    "embeddings = \"./extra/\"+filename.split(\".\")[0]+\"Embedding.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "752frames [00:34, 21.8frames/s]                      \n",
      "752frames [00:35, 21.4frames/s]                      \n",
      "752frames [00:31, 23.7frames/s]                     \n"
     ]
    }
   ],
   "source": [
    "\n",
    "video = Video(\"./video/\"+filename)\n",
    "do_shot(video, shotOutput)\n",
    "video = Video(\"./video/\"+filename)\n",
    "fc.track(video, shotOutput, tracking,detect_every=0.5)\n",
    "fc.extract(video, landmark_model,embedding_model, tracking, landmarks,embeddings)\n",
    "clustering = FaceClustering(threshold=0.6)\n",
    "face_tracks, embeddings = clustering.model.preprocess(embeddings)\n",
    "result = clustering(face_tracks, features=embeddings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "track=np.loadtxt(tracking,delimiter=\" \",dtype=str)\n",
    "tempArray=[]\n",
    "for segment, track_id, cluster in result.itertracks(yield_label=True):\n",
    "    tempArray.append([segment,track_id, cluster])\n",
    "tempArray=np.array(tempArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = Video(\"./video/\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "actorBasedShotArray=[]\n",
    "for u in np.unique(tempArray[:,2]):\n",
    "    actorBasedShotArray.append(tempArray[tempArray[:,2]==u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['t', 'track', 'left', 'top', 'right', 'bottom', 'status']\n",
    "dtype = {'left': np.float32, 'top': np.float32,\n",
    "         'right': np.float32, 'bottom': np.float32}\n",
    "tracking1 = read_table(tracking, delim_whitespace=True, header=None,\n",
    "                      names=names, dtype=dtype)\n",
    "tracking1 = tracking1.sort_values('t')\n",
    "del tracking1[\"status\"]\n",
    "del tracking1[\"track\"]\n",
    "tracking1=np.array(tracking1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uniqueActors=len(actorBasedShotArray)\n",
    "frame_width, frame_height = video.frame_size\n",
    "arraytosave=[]\n",
    "for i in range(uniqueActors):\n",
    "    startTime=actorBasedShotArray[i][0][0].start\n",
    "    image=video._get_frame(startTime)\n",
    "    faceDimension=tracking1[tracking1[:,0]==startTime][0]\n",
    "\n",
    "    left = int(faceDimension[1] * frame_width)\n",
    "    right = int(faceDimension[3] * frame_width)\n",
    "    top = int(faceDimension[2] * frame_height)\n",
    "    bottom = int(faceDimension[4] * frame_height)\n",
    "    Image.fromarray(misc.imresize(image[top:bottom,left:right,:], (180, 180), interp='bilinear'),'RGB').save(\"./output/actor\"+filename.split(\".\")[0]+str(i)+\".jpg\")\n",
    "    arraytosave.append([])\n",
    "    arraytosave[-1].append(\"actor\"+filename.split(\".\")[0]+str(i))\n",
    "    for j in actorBasedShotArray[i]:\n",
    "        arraytosave[-1].append(str(j[0].start)+\"*\"+str(j[0].end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actorsample40', '15.08*17.04']\n",
      "['actorsample41', '8.12*10.32', '10.36*12.64', '15.44*18.32', '22.72*24.08', '26.32*26.76', '26.56*30.0']\n",
      "['actorsample42', '6.36*10.32', '8.48*9.2', '12.68*15.04', '16.2*16.68', '16.36*17.64', '17.44*18.12', '19.8*24.08', '26.16*30.0']\n",
      "['actorsample43', '21.88*24.08', '24.12*26.12', '26.16*30.0']\n"
     ]
    }
   ],
   "source": [
    "outputFile=open(\"./output/\"+filename.split(\".\")[0]+\"output.txt\",'w')\n",
    "for item in arraytosave:\n",
    "    print item\n",
    "    outputFile.write(\"%s\\n\"%item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
